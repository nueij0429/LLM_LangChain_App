{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af9b8121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0693468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ee98644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a270f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001E858703290> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E858614A70> root_client=<openai.OpenAI object at 0x000001E858729310> root_async_client=<openai.AsyncOpenAI object at 0x000001E858700500> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e09ca344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 파이썬! 프로그래밍 세계에서 매우 인기 있는 언어입니다. 파이썬은 1991년에 네덜란드계 프로그래머인 귀도 반 로섬(Guido van Rossum)에 의해 개발되었습니다. 그는 ABC 프로그래밍 언어의 개발자였으며, 파이썬을 개발할 때 ABC의 장점을 계승하면서도 더 쉽고 직관적인 언어를 만들고자 했습니다.\n",
      "\n",
      "파이썬은 객체지향 프로그래밍 언어입니다. 이는 프로그래머가 데이터를 객체로 표현하고, 이 객체들이 상호작용하도록 프로그래밍할 수 있다는 것을 의미합니다. 파이썬은 또한 동적 타이핑 언어입니다. 이는 변수의 타입을 미리 선언할 필요가 없다는 것을 의미합니다.\n",
      "\n",
      "### 특징\n",
      "\n",
      "파이썬의 주요 특징 몇 가지를 소개해 드리겠습니다.\n",
      "\n",
      "1. **쉬운 학습 곡선**: 파이썬은 매우 직관적이고 읽기 쉬운 문법을 가지고 있습니다. 따라서 초보자가 프로그래밍을 시작할 때 매우 적합합니다.\n",
      "\n",
      "2. **대규모 라이브러리**: 파이썬은 방대한 표준 라이브러리와 외부 라이브러리를 보유하고 있습니다. 데이터 분석, 웹 개발, 인공지능, 과학 컴퓨팅 등 다양한 분야에서 사용할 수 있는 라이브러리가 있습니다.\n",
      "\n",
      "3. **플랫폼 독립성**: 파이썬은 플랫폼에 독립적입니다. 즉, 파이썬으로 작성된 프로그램은 Windows, macOS, Linux 등 다양한 운영체제에서 실행될 수 있습니다.\n",
      "\n",
      "4. **오픈 소스**: 파이썬은 오픈 소스 언어입니다. 소스 코드가 공개되어 있어 누구나 자유롭게 사용, 수정, 배포할 수 있습니다.\n",
      "\n",
      "5. **커뮤니티 지원**: 파이썬은 매우 활동적인 커뮤니티를 보유하고 있습니다. 개발자들이 자주 묻는 질문에 대한 답변, 코드 예제, 튜토리얼 등 다양한 자원을 온라인에서 쉽게 찾을 수 있습니다.\n",
      "\n",
      "### 응용 분야\n",
      "\n",
      "파이썬은 다양한 분야에서 사용됩니다.\n",
      "\n",
      "- **웹 개발**: 파이썬은 웹 개발을 위해 Django, Flask와 같은 인기 있는 프레임워크를 제공합니다.\n",
      "\n",
      "- **데이터 과학 및 인공지능**: NumPy, pandas, scikit-learn, TensorFlow, PyTorch와 같은 라이브러리를 통해 데이터 분석, 머신러닝, 딥러닝에 널리 사용됩니다.\n",
      "\n",
      "- **과학 컴퓨팅**: 과학적인 컴퓨팅을 위해 scipy, matplotlib와 같은 라이브러리가 제공됩니다.\n",
      "\n",
      "- **교육**: 파이썬의 간단한 문법과 강력한 라이브러리 지원으로 인해, 교육 현장에서 자주 사용됩니다.\n",
      "\n",
      "- **자동화**: 파이썬은 시스템 유틸리티, 데이터 처리, 자동화된 테스트와 같은 작업 자동화에 많이 사용됩니다.\n",
      "\n",
      "파이썬은 그 유연성과 강력한 기능으로 인해 프로그래밍 세계에서 매우 중요한 위치를 차지하고 있습니다. 초보자와 숙련된 개발자 모두에게 사랑받는 언어입니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750b360",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70824e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 설명해주세요.\"\\n    ')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 설명해주세요.\"\n",
    "    \"\"\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15b4b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e475b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 보여주면서 '이건 고양이야', '이건 강아지야'라고 알려주는 겁니다. \n",
      "\n",
      "모델은 이 데이터를 보고 스스로 특징을 찾습니다. '고양이는 귀가 뾰족하고 눈이 크다', '강아지는 귀가 쫑긋 서고 꼬리가 길다'와 같은 특징을 스스로 발견하는 거죠.\n",
      "\n",
      "이렇게 찾은 특징을 바탕으로 모델은 '고양이인지 강아지인지'를 구분하는 기준을 만듭니다. \n",
      "\n",
      "그런데 처음에는 이 기준이 정확하지 않을 수 있습니다. 그래서 모델은 계속해서 데이터를 보고 또 보고 하면서 자신의 기준을 조금씩 개선합니다.\n",
      "\n",
      "예를 들어, 처음에는 고양이 사진을 보고 '강아지야'라고 잘못 분류할 수 있습니다. 하지만 모델은 '아, 내가 잘못했구나'하고 깨닫고, 다음에는 좀 더 정확하게 분류하려고 노력합니다.\n",
      "\n",
      "이 과정을 반복하면서 모델은 점점 더 정확해지고, 결국에는 새로운 사진을 보고도 '이건 고양이야', '이건 강아지야'라고 정확하게 분류할 수 있게 됩니다.\n",
      "\n",
      "이처럼 인공지능 모델은 데이터를 통해 학습하고, 스스로 특징을 찾고, 기준을 만들어가는 과정을 통해 발전합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb99721",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OutputParser을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3c2d6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9eea99f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 다양한 AI 기반 제품 및 서비스를 제공하는 회사입니다. LangChain의 주요 제품은 다음과 같습니다:\n",
      "\n",
      "1. **LangChain**: 랭체인 플랫폼은 개발자가 자연어 처리(NLP) 모델을 쉽게 구축, 통합 및 배포할 수 있도록 지원하는 프레임워크입니다. 이 플랫폼은 사전 구축된 구성 요소와 툴을 제공하여 개발자가 대규모 언어 모델(LLM)을 활용할 수 있습니다.\n",
      "\n",
      "2. **LangServe**: LangServe는 LangChain을 기반으로 하는 API 서비스입니다. 이 서비스를 통해 개발자는 별도의 인프라를 구축하지 않고도 대규모 언어 모델을 쉽게 배포하고 사용할 수 있습니다.\n",
      "\n",
      "3. **LangSmith**: 랭스미스는 개발자가 LangChain을 사용하여 애플리케이션을 더 빠르게 구축할 수 있도록 지원하는 툴입니다. LangSmith를 사용하면 워크플로우 개발, 테스트 및 배포를 간소화할 수 있습니다.\n",
      "\n",
      "이러한 제품들은 LangChain이 제공하는 주요 서비스이며, 개발자가 자연어 처리 기능을 갖춘 애플리케이션을 더 쉽게 구축할 수 있도록 지원합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Products(제품)는 어떤 것들이 있나요?\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2945fc",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d29354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 사람은 경험을 통해 학습하고, 컴퓨터도 데이터를 통해 학습합니다.\n",
      "\n",
      "**인공지능 모델의 학습 과정**\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다. 이 데이터는 문제에 대한 답을 알고 있는 데이터여야 합니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 정제하고, 필요한 경우 데이터를 변환하여 인공지능 모델이 학습하기 쉽게 준비합니다.\n",
      "3. **모델 초기화**: 인공지능 모델을 초기화합니다. 이 단계에서는 모델의 구조와 가중치를 설정합니다.\n",
      "4. **학습**: 인공지능 모델이 수집한 데이터를 학습합니다. 이 단계에서는 모델이 데이터를 분석하고, 패턴을 발견하고, 가중치를 업데이트합니다.\n",
      "5. **평가**: 학습된 모델을 평가합니다. 이 단계에서는 모델의 성능을 측정하고, 모델이 얼마나 정확한지 확인합니다.\n",
      "\n",
      "**인공지능 모델의 학습 방법**\n",
      "\n",
      "인공지능 모델의 학습 방법에는 여러 가지가 있습니다. 대표적인 방법은 다음과 같습니다.\n",
      "\n",
      "1. **지도 학습**: 인공지능 모델에 데이터를 제공하고, 데이터에 대한 답을 알려주는 방법입니다. 이 방법을 통해 모델은 데이터와 답 사이의 관계를 학습합니다.\n",
      "2. **비지도 학습**: 인공지능 모델에 데이터를 제공하지만, 데이터에 대한 답을 알려주지 않는 방법입니다. 이 방법을 통해 모델은 데이터의 패턴을 스스로 발견합니다.\n",
      "3. **강화 학습**: 인공지능 모델이 환경과 상호작용하며, 보상을 최대화하는 방법입니다.\n",
      "\n",
      "**인공지능 모델의 학습 원리**\n",
      "\n",
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1. **오차 최소화**: 인공지능 모델은 예측한 값과 실제 값 사이의 오차를 최소화하려고 합니다.\n",
      "2. **가중치 업데이트**: 인공지능 모델은 학습 과정에서 가중치를 업데이트합니다. 이 가중치는 모델의 예측 성능을 결정합니다.\n",
      "3. **패턴 발견**: 인공지능 모델은 데이터에서 패턴을 발견하려고 합니다. 이 패턴을 통해 모델은 데이터를 분석하고, 예측합니다.\n",
      "\n",
      "예를 들어, 이미지 분류 인공지능 모델을 학습시킨다고 가정해 보겠습니다. 이 모델은 고양이, 개, 자동차 등의 이미지를 분류해야 합니다.\n",
      "\n",
      "* **데이터 수집**: 다양한 고양이, 개, 자동차 등의 이미지를 수집합니다.\n",
      "* **데이터 전처리**: 이미지를 정제하고, 크기를 조정합니다.\n",
      "* **모델 초기화**: 이미지 분류 모델을 초기화합니다.\n",
      "* **학습**: 모델이 이미지를 학습하고, 패턴을 발견합니다. 이 과정에서 모델은 가중치를 업데이트합니다.\n",
      "* **평가**: 모델의 성능을 평가합니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 학습하고, 패턴을 발견하고, 가중치를 업데이트하여 예측 성능을 향상합니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해주세요\"})\n",
    "\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0b5bd",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫번째 Chain의 출력이, 두번째 Chain의 입력이 된다.\n",
    "* 두개의 Chain과 Prompt + OutputParser를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45fc01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 10문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c2ac66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화의 제목은 '존 윅'입니다.\n",
      "\n",
      "전직 암살자 존 윅은 은퇴 후 평화로운 삶을 살고 있습니다.\n",
      "\n",
      "그는 아내를 먼저 잃고, 얼마 지나지 않아 암으로 아내가 사망합니다.\n",
      "\n",
      "존은 아내가 남긴 마지막 선물인 강아지 데이지와 함께 외로움을 달래고 있습니다.\n",
      "\n",
      "그런데, 존의 집에 무단 침입한 이오신(영고드)은 존의 차를 훔치고, 데이지까지 죽입니다.\n",
      "\n",
      "이오신은 고위 조직원인 산티아고의 아들이며, 존의 차는 산티아고가 선물로 준 차량입니다.\n",
      "\n",
      "존은 데이지의 죽음에 복수를 다짐하며, 전직 암살자의 삶을 다시 시작합니다.\n",
      "\n",
      "그는 산티아고의 조직과 전쟁을 벌이며, 많은 적들을 상대로 싸웁니다.\n",
      "\n",
      "존은 전 세계의 암살 조직들로부터 쫓기게 되며, 그의 목에는 엄청난 현상금이 걸립니다.\n",
      "\n",
      "존은 동료들의 도움을 받아가며, 산티아고와 그의 조직을 상대로 치열한 전투를 벌입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 입력 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"Action\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af7ac10",
   "metadata": {},
   "source": [
    "### PromptTemplate 여러 개 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "897f35e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "ChatGPT는 대규모 언어 데이터셋을 기반으로 하는 딥러닝 모델로서, 주어진 문맥에 따라 다음에 올 수 있는 단어를 예측하도록 학습합니다. 이를 위해 GPT 모델은 트랜스포머 아키텍처를 사용하며, 셀프 어텐션 메커니즘을 통해 입력 문장의 각 토큰 간의 관계를 모델링합니다. 학습 과정에서 모델은 언어 모델링 작업에 대한 손실을 최소화하도록 파라미터를 조정합니다.\n",
      "\n",
      "ChatGPT 모델의 장점은 다음과 같습니다.\n",
      "\n",
      "* 자연스럽고 유창한 텍스트 생성\n",
      "* 다양한 주제와 스타일에 대한 이해\n",
      "* 상황에 맞는 대화 가능\n",
      "* 높은 수준의 언어 이해 능력\n",
      "\n",
      "ChatGPT 모델과 비슷한 AI 모델은 다음과 있습니다.\n",
      "\n",
      "* BERT\n",
      "* RoBERTa\n",
      "* LLaMA\n",
      "* PaLM\n",
      "\n",
      "이러한 모델들은 대부분 트랜스포머 아키텍처를 기반으로 하며, 자연어 처리 작업에 뛰어난 성능을 발휘합니다.\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 요약해서 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70d3d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.', 'Gemma 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'llama-4 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemma\", \"count\": 3},\n",
    "    {\"model_name\": \"llama-4\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "547b9a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='GPT-4 모델은 대규모의 텍스트 데이터를 학습하여 언어 패턴과 구조를 익히는 방식으로 훈련됩니다. 이 모델은 주어진 문맥에서 다음에 올 가능성이 높은 단어를 예측하도록 설계되었으며, 이를 통해 자연스러운 텍스트를 생성하거나 주어진 질문에 답변할 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 28, 'total_tokens': 89, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.37781006500000003, 'prompt_time': 0.002923378, 'completion_time': 0.147120252, 'total_time': 0.15004363}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-282ead74-8017-475c-9970-86f2959d8892', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--6e3391b2-a4e4-4f57-a719-3de31bee1d2b-0' usage_metadata={'input_tokens': 28, 'output_tokens': 61, 'total_tokens': 89, 'input_token_details': {}, 'output_token_details': {}}\n",
      "content='Gemma는 컴퓨터가 자연어 작업을 더 잘 수행하도록 돕는 언어 모델입니다. 텍스트의 통계와 패턴을 학습하여 예측을 수행하는 방법을 배우는 머신러닝 알고리즘을 사용합니다. 이 학습 프로세스는 많은 양의 텍스트 데이터에 대한 교육을 통해 이루어집니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 59, 'prompt_tokens': 27, 'total_tokens': 86, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.34626035800000005, 'prompt_time': 0.002931598, 'completion_time': 0.140381372, 'total_time': 0.14331297}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-22cb8d14-2ddc-4fc3-929c-ef762138690f', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--a53e3546-43fe-44fe-a57e-633b9e316963-0' usage_metadata={'input_tokens': 27, 'output_tokens': 59, 'total_tokens': 86, 'input_token_details': {}, 'output_token_details': {}}\n",
      "content='llama-4 모델은 메타에서 개발한 대규모 언어 모델입니다. 이 모델은 방대한 양의 텍스트 데이터를 기반으로 학습되며, 이를 통해 자연어 처리 능력을 습득합니다. 학습 과정에서 모델은 주어진 문맥에서 다음에 올 가능성이 높은 단어를 예측하도록 훈련되며, 이 과정을 통해 언어의 패턴과 구조를 학습합니다. 이를 통해 llama-4 모델은 다양한 자연어 처리 작업에 활용될 수 있습니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 29, 'total_tokens': 119, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.27866622799999996, 'prompt_time': 0.003018367, 'completion_time': 0.215626779, 'total_time': 0.218645146}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-a3edc413-48f0-480a-a7db-17e0661f5451', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--22145599-593e-460f-8b35-7e16ad681d34-0' usage_metadata={'input_tokens': 29, 'output_tokens': 90, 'total_tokens': 119, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    response = llm.invoke(prompt)\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f796de",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate, HumanMessagePromptTemplate, AIMessagePromptTemplate 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f44f16cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I wrote it to provide a comprehensive overview of deep learning.\n",
      "\n",
      "**Deep Learning: A Comprehensive Overview**\n",
      "=====================================\n",
      "\n",
      "### Introduction\n",
      "\n",
      "Deep learning is a subset of machine learning, which is a type of artificial intelligence (AI) that enables computers to learn from data without being explicitly programmed. It is a key technology behind many recent advances in AI, including image and speech recognition, natural language processing, and autonomous vehicles.\n",
      "\n",
      "### What is Deep Learning?\n",
      "\n",
      "Deep learning is a type of machine learning that uses neural networks to analyze data. A neural network is a computer system inspired by the structure and function of the human brain. It consists of layers of interconnected nodes or \"neurons,\" which process and transmit information.\n",
      "\n",
      "In traditional machine learning, a computer is trained on a dataset and then uses that training to make predictions on new, unseen data. In deep learning, the computer is trained on a large dataset and learns to represent the data in a hierarchical manner, with early layers learning low-level features and later layers learning higher-level features.\n",
      "\n",
      "### Key Characteristics of Deep Learning\n",
      "\n",
      "* **Multiple Layers**: Deep learning models typically have multiple layers, which allow them to learn complex patterns in data.\n",
      "* **Neural Networks**: Deep learning models are based on neural networks, which are composed of nodes or \"neurons\" that process and transmit information.\n",
      "* **Large Datasets**: Deep learning models require large amounts of data to train effectively.\n",
      "* **Computational Power**: Deep learning models require significant computational power to train and deploy.\n",
      "\n",
      "### Types of Deep Learning Models\n",
      "\n",
      "* **Convolutional Neural Networks (CNNs)**: CNNs are commonly used for image and video analysis tasks, such as image classification, object detection, and image segmentation.\n",
      "* **Recurrent Neural Networks (RNNs)**: RNNs are commonly used for sequential data, such as speech, text, and time series data.\n",
      "* **Autoencoders**: Autoencoders are used for unsupervised learning tasks, such as dimensionality reduction and anomaly detection.\n",
      "\n",
      "### Applications of Deep Learning\n",
      "\n",
      "* **Computer Vision**: Deep learning is widely used in computer vision applications, such as image recognition, object detection, and image segmentation.\n",
      "* **Natural Language Processing**: Deep learning is used in natural language processing applications, such as language translation, sentiment analysis, and text summarization.\n",
      "* **Speech Recognition**: Deep learning is used in speech recognition applications, such as voice assistants and speech-to-text systems.\n",
      "\n",
      "### Benefits of Deep Learning\n",
      "\n",
      "* **Improved Accuracy**: Deep learning models can achieve state-of-the-art accuracy on many tasks.\n",
      "* **Flexibility**: Deep learning models can be applied to a wide range of tasks and domains.\n",
      "* **Scalability**: Deep learning models can be scaled up to handle large datasets and complex tasks.\n",
      "\n",
      "### Challenges of Deep Learning\n",
      "\n",
      "* **Data Requirements**: Deep learning models require large amounts of data to train effectively.\n",
      "* **Computational Power**: Deep learning models require significant computational power to train and deploy.\n",
      "* **Interpretability**: Deep learning models can be difficult to interpret and understand.\n",
      "\n",
      "### Conclusion\n",
      "\n",
      "Deep learning is a powerful technology that has enabled many recent advances in AI. Its ability to learn complex patterns in data has made it a key tool in many applications, from computer vision and natural language processing to speech recognition and autonomous vehicles. However, deep learning also presents challenges, such as data requirements and computational power, that must be addressed in order to fully realize its potential.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an {topic} expert. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "llm = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a6ded5",
   "metadata": {},
   "source": [
    "### FewShotPromptTemplate\n",
    "* 예시를 제공 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d9c8db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 태양계 행성\n",
      "1. **수성**: 태양과 가장 가까운 행성으로, 매우 작고 온도가 극심하게 변합니다.\n",
      "2. **금성**: 밝고 뜨거운 행성으로, 강한 온실 효과로 표면 온도가 매우 높습니다.\n",
      "3. **지구**: 생명체가 존재하는 유일한 행성으로, 대기 구성과 물이 있습니다.\n",
      "4. **화성**: 붉은 행성으로, 과거에는 물이 있었다고 추정되며 현재 탐사가 진행 중입니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성으로, 가스 행성입니다.\n",
      "6. **토성**: 아름다운 고리를 가진 가스 행성입니다.\n",
      "7. **천왕성**: 빙하 행성으로, 자전축이 기울어져 있습니다.\n",
      "8. **해왕성**: 가장 먼 행성으로, 강한 바람과 추운 온도를 가지고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "chain = final_prompt | model\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "#result = chain.invoke({\"input\": \"양자 얽힘이 무엇인가요?\"})\n",
    "print(result.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
