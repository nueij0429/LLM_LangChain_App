{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af9b8121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0693468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ee98644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a270f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001E858703290> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E858614A70> root_client=<openai.OpenAI object at 0x000001E858729310> root_async_client=<openai.AsyncOpenAI object at 0x000001E858700500> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e09ca344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 파이썬! 프로그래밍 세계에서 매우 인기 있는 언어입니다. 파이썬은 1991년에 네덜란드계 프로그래머인 귀도 반 로섬(Guido van Rossum)에 의해 개발되었습니다. 그는 ABC 프로그래밍 언어의 개발자였으며, 파이썬을 개발할 때 ABC의 장점을 계승하면서도 더 쉽고 직관적인 언어를 만들고자 했습니다.\n",
      "\n",
      "파이썬은 객체지향 프로그래밍 언어입니다. 이는 프로그래머가 데이터를 객체로 표현하고, 이 객체들이 상호작용하도록 프로그래밍할 수 있다는 것을 의미합니다. 파이썬은 또한 동적 타이핑 언어입니다. 이는 변수의 타입을 미리 선언할 필요가 없다는 것을 의미합니다.\n",
      "\n",
      "### 특징\n",
      "\n",
      "파이썬의 주요 특징 몇 가지를 소개해 드리겠습니다.\n",
      "\n",
      "1. **쉬운 학습 곡선**: 파이썬은 매우 직관적이고 읽기 쉬운 문법을 가지고 있습니다. 따라서 초보자가 프로그래밍을 시작할 때 매우 적합합니다.\n",
      "\n",
      "2. **대규모 라이브러리**: 파이썬은 방대한 표준 라이브러리와 외부 라이브러리를 보유하고 있습니다. 데이터 분석, 웹 개발, 인공지능, 과학 컴퓨팅 등 다양한 분야에서 사용할 수 있는 라이브러리가 있습니다.\n",
      "\n",
      "3. **플랫폼 독립성**: 파이썬은 플랫폼에 독립적입니다. 즉, 파이썬으로 작성된 프로그램은 Windows, macOS, Linux 등 다양한 운영체제에서 실행될 수 있습니다.\n",
      "\n",
      "4. **오픈 소스**: 파이썬은 오픈 소스 언어입니다. 소스 코드가 공개되어 있어 누구나 자유롭게 사용, 수정, 배포할 수 있습니다.\n",
      "\n",
      "5. **커뮤니티 지원**: 파이썬은 매우 활동적인 커뮤니티를 보유하고 있습니다. 개발자들이 자주 묻는 질문에 대한 답변, 코드 예제, 튜토리얼 등 다양한 자원을 온라인에서 쉽게 찾을 수 있습니다.\n",
      "\n",
      "### 응용 분야\n",
      "\n",
      "파이썬은 다양한 분야에서 사용됩니다.\n",
      "\n",
      "- **웹 개발**: 파이썬은 웹 개발을 위해 Django, Flask와 같은 인기 있는 프레임워크를 제공합니다.\n",
      "\n",
      "- **데이터 과학 및 인공지능**: NumPy, pandas, scikit-learn, TensorFlow, PyTorch와 같은 라이브러리를 통해 데이터 분석, 머신러닝, 딥러닝에 널리 사용됩니다.\n",
      "\n",
      "- **과학 컴퓨팅**: 과학적인 컴퓨팅을 위해 scipy, matplotlib와 같은 라이브러리가 제공됩니다.\n",
      "\n",
      "- **교육**: 파이썬의 간단한 문법과 강력한 라이브러리 지원으로 인해, 교육 현장에서 자주 사용됩니다.\n",
      "\n",
      "- **자동화**: 파이썬은 시스템 유틸리티, 데이터 처리, 자동화된 테스트와 같은 작업 자동화에 많이 사용됩니다.\n",
      "\n",
      "파이썬은 그 유연성과 강력한 기능으로 인해 프로그래밍 세계에서 매우 중요한 위치를 차지하고 있습니다. 초보자와 숙련된 개발자 모두에게 사랑받는 언어입니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750b360",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70824e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 설명해주세요.\"\\n    ')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 설명해주세요.\"\n",
    "    \"\"\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15b4b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e475b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 보여주면서 '이건 고양이야', '이건 강아지야'라고 알려주는 겁니다. \n",
      "\n",
      "모델은 이 데이터를 보고 스스로 특징을 찾습니다. '고양이는 귀가 뾰족하고 눈이 크다', '강아지는 귀가 쫑긋 서고 꼬리가 길다'와 같은 특징을 스스로 발견하는 거죠.\n",
      "\n",
      "이렇게 찾은 특징을 바탕으로 모델은 '고양이인지 강아지인지'를 구분하는 기준을 만듭니다. \n",
      "\n",
      "그런데 처음에는 이 기준이 정확하지 않을 수 있습니다. 그래서 모델은 계속해서 데이터를 보고 또 보고 하면서 자신의 기준을 조금씩 개선합니다.\n",
      "\n",
      "예를 들어, 처음에는 고양이 사진을 보고 '강아지야'라고 잘못 분류할 수 있습니다. 하지만 모델은 '아, 내가 잘못했구나'하고 깨닫고, 다음에는 좀 더 정확하게 분류하려고 노력합니다.\n",
      "\n",
      "이 과정을 반복하면서 모델은 점점 더 정확해지고, 결국에는 새로운 사진을 보고도 '이건 고양이야', '이건 강아지야'라고 정확하게 분류할 수 있게 됩니다.\n",
      "\n",
      "이처럼 인공지능 모델은 데이터를 통해 학습하고, 스스로 특징을 찾고, 기준을 만들어가는 과정을 통해 발전합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb99721",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OutputParser을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3c2d6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9eea99f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 다양한 AI 기반 제품 및 서비스를 제공하는 회사입니다. LangChain의 주요 제품은 다음과 같습니다:\n",
      "\n",
      "1. **LangChain**: 랭체인 플랫폼은 개발자가 자연어 처리(NLP) 모델을 쉽게 구축, 통합 및 배포할 수 있도록 지원하는 프레임워크입니다. 이 플랫폼은 사전 구축된 구성 요소와 툴을 제공하여 개발자가 대규모 언어 모델(LLM)을 활용할 수 있습니다.\n",
      "\n",
      "2. **LangServe**: LangServe는 LangChain을 기반으로 하는 API 서비스입니다. 이 서비스를 통해 개발자는 별도의 인프라를 구축하지 않고도 대규모 언어 모델을 쉽게 배포하고 사용할 수 있습니다.\n",
      "\n",
      "3. **LangSmith**: 랭스미스는 개발자가 LangChain을 사용하여 애플리케이션을 더 빠르게 구축할 수 있도록 지원하는 툴입니다. LangSmith를 사용하면 워크플로우 개발, 테스트 및 배포를 간소화할 수 있습니다.\n",
      "\n",
      "이러한 제품들은 LangChain이 제공하는 주요 서비스이며, 개발자가 자연어 처리 기능을 갖춘 애플리케이션을 더 쉽게 구축할 수 있도록 지원합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Products(제품)는 어떤 것들이 있나요?\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2945fc",
   "metadata": {},
   "source": [
    "### Runnable의 stream() 함수 호출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d29354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리를 쉽게 설명해 드리겠습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. 사람은 경험을 통해 학습하고, 컴퓨터도 데이터를 통해 학습합니다.\n",
      "\n",
      "**인공지능 모델의 학습 과정**\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 필요한 데이터를 수집합니다. 이 데이터는 문제에 대한 답을 알고 있는 데이터여야 합니다.\n",
      "2. **데이터 전처리**: 수집한 데이터를 정제하고, 필요한 경우 데이터를 변환하여 인공지능 모델이 학습하기 쉽게 준비합니다.\n",
      "3. **모델 초기화**: 인공지능 모델을 초기화합니다. 이 단계에서는 모델의 구조와 가중치를 설정합니다.\n",
      "4. **학습**: 인공지능 모델이 수집한 데이터를 학습합니다. 이 단계에서는 모델이 데이터를 분석하고, 패턴을 발견하고, 가중치를 업데이트합니다.\n",
      "5. **평가**: 학습된 모델을 평가합니다. 이 단계에서는 모델의 성능을 측정하고, 모델이 얼마나 정확한지 확인합니다.\n",
      "\n",
      "**인공지능 모델의 학습 방법**\n",
      "\n",
      "인공지능 모델의 학습 방법에는 여러 가지가 있습니다. 대표적인 방법은 다음과 같습니다.\n",
      "\n",
      "1. **지도 학습**: 인공지능 모델에 데이터를 제공하고, 데이터에 대한 답을 알려주는 방법입니다. 이 방법을 통해 모델은 데이터와 답 사이의 관계를 학습합니다.\n",
      "2. **비지도 학습**: 인공지능 모델에 데이터를 제공하지만, 데이터에 대한 답을 알려주지 않는 방법입니다. 이 방법을 통해 모델은 데이터의 패턴을 스스로 발견합니다.\n",
      "3. **강화 학습**: 인공지능 모델이 환경과 상호작용하며, 보상을 최대화하는 방법입니다.\n",
      "\n",
      "**인공지능 모델의 학습 원리**\n",
      "\n",
      "인공지능 모델의 학습 원리는 다음과 같습니다.\n",
      "\n",
      "1. **오차 최소화**: 인공지능 모델은 예측한 값과 실제 값 사이의 오차를 최소화하려고 합니다.\n",
      "2. **가중치 업데이트**: 인공지능 모델은 학습 과정에서 가중치를 업데이트합니다. 이 가중치는 모델의 예측 성능을 결정합니다.\n",
      "3. **패턴 발견**: 인공지능 모델은 데이터에서 패턴을 발견하려고 합니다. 이 패턴을 통해 모델은 데이터를 분석하고, 예측합니다.\n",
      "\n",
      "예를 들어, 이미지 분류 인공지능 모델을 학습시킨다고 가정해 보겠습니다. 이 모델은 고양이, 개, 자동차 등의 이미지를 분류해야 합니다.\n",
      "\n",
      "* **데이터 수집**: 다양한 고양이, 개, 자동차 등의 이미지를 수집합니다.\n",
      "* **데이터 전처리**: 이미지를 정제하고, 크기를 조정합니다.\n",
      "* **모델 초기화**: 이미지 분류 모델을 초기화합니다.\n",
      "* **학습**: 모델이 이미지를 학습하고, 패턴을 발견합니다. 이 과정에서 모델은 가중치를 업데이트합니다.\n",
      "* **평가**: 모델의 성능을 평가합니다.\n",
      "\n",
      "이렇게 인공지능 모델은 데이터를 학습하고, 패턴을 발견하고, 가중치를 업데이트하여 예측 성능을 향상합니다."
     ]
    }
   ],
   "source": [
    "# 스트리밍 출력을 위한 요청\n",
    "try:\n",
    "    answer = chain2.stream({\"input\": \"인공지능 모델의 학습 원리를 자세하게 설명해주세요\"})\n",
    "\n",
    "    for token in answer:\n",
    "        # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "        print(token, end=\"\", flush=True)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c0b5bd",
   "metadata": {},
   "source": [
    "### Multi Chain\n",
    "* 첫번째 Chain의 출력이, 두번째 Chain의 입력이 된다.\n",
    "* 두개의 Chain과 Prompt + OutputParser를 LCEL로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "45fc01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추전한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 줄거리를 10문장으로 요약해 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4c2ac66a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영화의 제목은 '존 윅'입니다.\n",
      "\n",
      "전직 암살자 존 윅은 은퇴 후 평화로운 삶을 살고 있습니다.\n",
      "\n",
      "그는 아내를 먼저 잃고, 얼마 지나지 않아 암으로 아내가 사망합니다.\n",
      "\n",
      "존은 아내가 남긴 마지막 선물인 강아지 데이지와 함께 외로움을 달래고 있습니다.\n",
      "\n",
      "그런데, 존의 집에 무단 침입한 이오신(영고드)은 존의 차를 훔치고, 데이지까지 죽입니다.\n",
      "\n",
      "이오신은 고위 조직원인 산티아고의 아들이며, 존의 차는 산티아고가 선물로 준 차량입니다.\n",
      "\n",
      "존은 데이지의 죽음에 복수를 다짐하며, 전직 암살자의 삶을 다시 시작합니다.\n",
      "\n",
      "그는 산티아고의 조직과 전쟁을 벌이며, 많은 적들을 상대로 싸웁니다.\n",
      "\n",
      "존은 전 세계의 암살 조직들로부터 쫓기게 되며, 그의 목에는 엄청난 현상금이 걸립니다.\n",
      "\n",
      "존은 동료들의 도움을 받아가며, 산티아고와 그의 조직을 상대로 치열한 전투를 벌입니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "try:\n",
    "    chain2 = (\n",
    "        {\"movie\": chain1}  # chain1의 출력을 movie 입력 변수로 전달\n",
    "        | prompt2\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    # 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "    response = chain2.invoke({\"genre\": \"Action\"})\n",
    "    print(response)  \n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7c5bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
