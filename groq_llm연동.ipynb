{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af9b8121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello LangChain\n"
     ]
    }
   ],
   "source": [
    "print('Hello LangChain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0693468d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI \n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ee98644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['input'] input_types={} partial_variables={} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 개발자입니다.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "# prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [ (\"system\", \"당신은 개발자입니다.\") , \n",
    "     (\"user\", \"{input}\") ]\n",
    ")\n",
    "print(prompt)\n",
    "\n",
    "prompt_text = prompt.format(input=\"파이썬은 무엇인가요? 자세하게 설명해주세요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c8a270f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000001E858703290> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001E858614A70> root_client=<openai.OpenAI object at 0x000001E858729310> root_async_client=<openai.AsyncOpenAI object at 0x000001E858700500> model_name='meta-llama/llama-4-scout-17b-16e-instruct' temperature=0.7 model_kwargs={} openai_api_key=SecretStr('**********') openai_api_base='https://api.groq.com/openai/v1'\n"
     ]
    }
   ],
   "source": [
    "# Groq API를 사용하는 ChatOpenAI 인스턴스 생성\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0.7\n",
    ")\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e09ca344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답: 파이썬! 프로그래밍 세계에서 매우 인기 있는 언어입니다. 파이썬은 1991년에 네덜란드계 프로그래머인 귀도 반 로섬(Guido van Rossum)에 의해 개발되었습니다. 그는 ABC 프로그래밍 언어의 개발자였으며, 파이썬을 개발할 때 ABC의 장점을 계승하면서도 더 쉽고 직관적인 언어를 만들고자 했습니다.\n",
      "\n",
      "파이썬은 객체지향 프로그래밍 언어입니다. 이는 프로그래머가 데이터를 객체로 표현하고, 이 객체들이 상호작용하도록 프로그래밍할 수 있다는 것을 의미합니다. 파이썬은 또한 동적 타이핑 언어입니다. 이는 변수의 타입을 미리 선언할 필요가 없다는 것을 의미합니다.\n",
      "\n",
      "### 특징\n",
      "\n",
      "파이썬의 주요 특징 몇 가지를 소개해 드리겠습니다.\n",
      "\n",
      "1. **쉬운 학습 곡선**: 파이썬은 매우 직관적이고 읽기 쉬운 문법을 가지고 있습니다. 따라서 초보자가 프로그래밍을 시작할 때 매우 적합합니다.\n",
      "\n",
      "2. **대규모 라이브러리**: 파이썬은 방대한 표준 라이브러리와 외부 라이브러리를 보유하고 있습니다. 데이터 분석, 웹 개발, 인공지능, 과학 컴퓨팅 등 다양한 분야에서 사용할 수 있는 라이브러리가 있습니다.\n",
      "\n",
      "3. **플랫폼 독립성**: 파이썬은 플랫폼에 독립적입니다. 즉, 파이썬으로 작성된 프로그램은 Windows, macOS, Linux 등 다양한 운영체제에서 실행될 수 있습니다.\n",
      "\n",
      "4. **오픈 소스**: 파이썬은 오픈 소스 언어입니다. 소스 코드가 공개되어 있어 누구나 자유롭게 사용, 수정, 배포할 수 있습니다.\n",
      "\n",
      "5. **커뮤니티 지원**: 파이썬은 매우 활동적인 커뮤니티를 보유하고 있습니다. 개발자들이 자주 묻는 질문에 대한 답변, 코드 예제, 튜토리얼 등 다양한 자원을 온라인에서 쉽게 찾을 수 있습니다.\n",
      "\n",
      "### 응용 분야\n",
      "\n",
      "파이썬은 다양한 분야에서 사용됩니다.\n",
      "\n",
      "- **웹 개발**: 파이썬은 웹 개발을 위해 Django, Flask와 같은 인기 있는 프레임워크를 제공합니다.\n",
      "\n",
      "- **데이터 과학 및 인공지능**: NumPy, pandas, scikit-learn, TensorFlow, PyTorch와 같은 라이브러리를 통해 데이터 분석, 머신러닝, 딥러닝에 널리 사용됩니다.\n",
      "\n",
      "- **과학 컴퓨팅**: 과학적인 컴퓨팅을 위해 scipy, matplotlib와 같은 라이브러리가 제공됩니다.\n",
      "\n",
      "- **교육**: 파이썬의 간단한 문법과 강력한 라이브러리 지원으로 인해, 교육 현장에서 자주 사용됩니다.\n",
      "\n",
      "- **자동화**: 파이썬은 시스템 유틸리티, 데이터 처리, 자동화된 테스트와 같은 작업 자동화에 많이 사용됩니다.\n",
      "\n",
      "파이썬은 그 유연성과 강력한 기능으로 인해 프로그래밍 세계에서 매우 중요한 위치를 차지하고 있습니다. 초보자와 숙련된 개발자 모두에게 사랑받는 언어입니다.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    response = llm.invoke(prompt_text)\n",
    "    print(\"응답:\", response.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c750b360",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "70824e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='\\n    You are an expert in AI Expert. Answer the question. \\n    <Question>: {input}에 대해 쉽게 설명해주세요.\"\\n    ')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    You are an expert in AI Expert. Answer the question. \n",
    "    <Question>: {input}에 대해 쉽게 설명해주세요.\"\n",
    "    \"\"\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15b4b6a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e475b6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 방식과 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 고양이와 강아지의 사진을 보여주면서 '이건 고양이야', '이건 강아지야'라고 알려주는 겁니다. \n",
      "\n",
      "모델은 이 데이터를 보고 스스로 특징을 찾습니다. '고양이는 귀가 뾰족하고 눈이 크다', '강아지는 귀가 쫑긋 서고 꼬리가 길다'와 같은 특징을 스스로 발견하는 거죠.\n",
      "\n",
      "이렇게 찾은 특징을 바탕으로 모델은 '고양이인지 강아지인지'를 구분하는 기준을 만듭니다. \n",
      "\n",
      "그런데 처음에는 이 기준이 정확하지 않을 수 있습니다. 그래서 모델은 계속해서 데이터를 보고 또 보고 하면서 자신의 기준을 조금씩 개선합니다.\n",
      "\n",
      "예를 들어, 처음에는 고양이 사진을 보고 '강아지야'라고 잘못 분류할 수 있습니다. 하지만 모델은 '아, 내가 잘못했구나'하고 깨닫고, 다음에는 좀 더 정확하게 분류하려고 노력합니다.\n",
      "\n",
      "이 과정을 반복하면서 모델은 점점 더 정확해지고, 결국에는 새로운 사진을 보고도 '이건 고양이야', '이건 강아지야'라고 정확하게 분류할 수 있게 됩니다.\n",
      "\n",
      "이처럼 인공지능 모델은 데이터를 통해 학습하고, 스스로 특징을 찾고, 기준을 만들어가는 과정을 통해 발전합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "    print(type(result))\n",
    "    print(result.content)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb99721",
   "metadata": {},
   "source": [
    "### LCEL\n",
    "* Prompt + LLM + OutputParser을 Chain으로 연결하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3c2d6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain2 = prompt | llm | output_parser\n",
    "print(type(chain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9eea99f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "LangChain은 다양한 AI 기반 제품 및 서비스를 제공하는 회사입니다. LangChain의 주요 제품은 다음과 같습니다:\n",
      "\n",
      "1. **LangChain**: 랭체인 플랫폼은 개발자가 자연어 처리(NLP) 모델을 쉽게 구축, 통합 및 배포할 수 있도록 지원하는 프레임워크입니다. 이 플랫폼은 사전 구축된 구성 요소와 툴을 제공하여 개발자가 대규모 언어 모델(LLM)을 활용할 수 있습니다.\n",
      "\n",
      "2. **LangServe**: LangServe는 LangChain을 기반으로 하는 API 서비스입니다. 이 서비스를 통해 개발자는 별도의 인프라를 구축하지 않고도 대규모 언어 모델을 쉽게 배포하고 사용할 수 있습니다.\n",
      "\n",
      "3. **LangSmith**: 랭스미스는 개발자가 LangChain을 사용하여 애플리케이션을 더 빠르게 구축할 수 있도록 지원하는 툴입니다. LangSmith를 사용하면 워크플로우 개발, 테스트 및 배포를 간소화할 수 있습니다.\n",
      "\n",
      "이러한 제품들은 LangChain이 제공하는 주요 서비스이며, 개발자가 자연어 처리 기능을 갖춘 애플리케이션을 더 쉽게 구축할 수 있도록 지원합니다.\n"
     ]
    }
   ],
   "source": [
    "# chain 호출\n",
    "try:\n",
    "    result = chain2.invoke({\"input\": \"LangChain의 Products(제품)는 어떤 것들이 있나요?\"})\n",
    "    print(type(result))\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"오류 발생: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
