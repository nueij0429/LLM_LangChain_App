{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db488d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720e6ea",
   "metadata": {},
   "source": [
    "### CommaSeparatedListOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f768644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\n",
      "['Machine Learning', 'Deep Learning', 'Natural Language Processing', 'Computer Vision', 'Robotics']\n",
      " 'ai_technologies.csv' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import csv\n",
    "from pprint import pprint\n",
    "\n",
    "# ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ ê°€ì ¸ì˜¤ê¸°\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"List five {subject}.\\n{format_instructions}\",\n",
    "    input_variables=[\"subject\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "pprint(prompt)\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "#model = ChatOpenAI(temperature=0)\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ì—¬ ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "# \"AI ê´€ë ¨ ê¸°ìˆ \"ì— ëŒ€í•œ ì²´ì¸ í˜¸ì¶œ ì‹¤í–‰\n",
    "result = chain.invoke({\"subject\": \"AI ê´€ë ¨ ê¸°ìˆ \"})\n",
    "\n",
    "# ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ë¦¬ìŠ¤íŠ¸ ì¶œë ¥\n",
    "print(\" AI ê´€ë ¨ ê¸°ìˆ  ëª©ë¡:\")\n",
    "print(result)\n",
    "\n",
    "# ê²°ê³¼ í™œìš© ì˜ˆì‹œ: CSV íŒŒì¼ë¡œ ì €ì¥\n",
    "csv_filename = \"./data/ai_technologies.csv\"\n",
    "with open(csv_filename, \"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"AI ê¸°ìˆ \"])  # í—¤ë” ì¶”ê°€\n",
    "    for item in result:\n",
    "        writer.writerow([item])\n",
    "\n",
    "print(f\" '{csv_filename}' íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f84baa",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d38efcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"mission_name\": \"ë‰´í˜¸ë¼ì´ì¦ŒìŠ¤\",\n",
      "        \"goal\": \"ëª…ì™•ì„± íƒì‚¬\",\n",
      "        \"agency\": \"NASA\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì¹´ì‹œë‹ˆ-í˜¸ì´ê²ìŠ¤\",\n",
      "        \"goal\": \"í† ì„±ì˜ ìœ„ì„± íƒ€ì´íƒ„ íƒì‚¬\",\n",
      "        \"agency\": \"NASA, ESA, ì´íƒˆë¦¬ì•„ ìš°ì£¼êµ­\"\n",
      "    },\n",
      "    {\n",
      "        \"mission_name\": \"ì°½ì–´ 4í˜¸\",\n",
      "        \"goal\": \"ë‹¬ì˜ ë’·ë©´ íƒì‚¬\",\n",
      "        \"agency\": \"ì¤‘êµ­ ìš°ì£¼êµ­\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# JSON ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì„ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"ë‹¹ì‹ ì€ ê³¼í•™ ë¶„ì•¼ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ì§ˆë¬¸ì— ëŒ€í•´ ì²´ê³„ì ì´ê³  ê°„ê²°í•œ ë‹µë³€ì„ JSON í˜•ì‹ìœ¼ë¡œ ì œê³µí•˜ì„¸ìš”.\"),\n",
    "        (\"user\", \"#Format: {format_instructions}\\n\\n#Question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# JSON ì¶œë ¥ í˜•ì‹ ì§€ì¹¨ì„ í”„ë¡¬í”„íŠ¸ì— ì ìš©\n",
    "prompt = prompt.partial(format_instructions=parser.get_format_instructions())\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì„¤ì •\n",
    "model = ChatOpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸, ëª¨ë¸, ì¶œë ¥ íŒŒì„œë¥¼ ì—°ê²°í•˜ëŠ” ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì§ˆë¬¸ ì„¤ì • (ìš°ì£¼ íƒì‚¬ ê´€ë ¨ ì§ˆë¬¸)\n",
    "question = \"ìµœê·¼ 10ë…„ê°„ ì§„í–‰ëœ ì£¼ìš” ìš°ì£¼ íƒì‚¬ ë¯¸ì…˜ 3ê°€ì§€ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”. \\\n",
    "ê° ë¯¸ì…˜ì˜ ì´ë¦„ì€ `mission_name`ì—, ëª©í‘œëŠ” `goal`ì—, ì£¼ê´€ ê¸°ê´€ì€ `agency`ì— ë‹´ì•„ ì£¼ì„¸ìš”.\"\n",
    "\n",
    "# ì²´ì¸ ì‹¤í–‰ ë° JSON ì‘ë‹µ ë°›ê¸°\n",
    "response = chain.invoke({\"question\": question})\n",
    "\n",
    "# JSON ë°ì´í„° ì¶œë ¥\n",
    "print(json.dumps(response, indent=4, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f9ebec",
   "metadata": {},
   "source": [
    "### PandasDataFrameOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfe4edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import PandasDataFrameOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "import re\n",
    "\n",
    "# Titanic ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "df = pd.read_csv('data/titanic.csv')\n",
    "\n",
    "# Pandas DataFrame Output Parser ì„¤ì •\n",
    "parser = PandasDataFrameOutputParser(dataframe=df)\n",
    "# í˜•ì‹ ì§€ì¹¨ ì¶œë ¥\n",
    "format_instructions = parser.get_format_instructions()\n",
    "#print(\"Format Instructions:\\n\", format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda52a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived, Pclass, Name, Sex, Age, Siblings/Spouses Aboard, Parents/Children Aboard, Fare\n"
     ]
    }
   ],
   "source": [
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" \n",
    "    You are a helpful assistant that interacts with a Pandas DataFrame.\n",
    "    The DataFrame contains the following columns: {columns}.\n",
    "    \n",
    "    Your task is to answer the user's query by generating a command in the following format:\n",
    "    {format_instructions}\n",
    "    \n",
    "    User Query: {query}    \n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": format_instructions,\n",
    "        \"columns\": \", \".join(df.columns)\n",
    "    },\n",
    ")\n",
    "print(prompt.partial_variables['columns'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7d2dbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name ì»¬ëŸ¼ ì¶œë ¥\n",
      "<class 'dict'>\n",
      "{'Name': 0                                 Mr. Owen Harris Braund\n",
      "1      Mrs. John Bradley (Florence Briggs Thayer) Cum...\n",
      "2                                  Miss. Laina Heikkinen\n",
      "3            Mrs. Jacques Heath (Lily May Peel) Futrelle\n",
      "4                                Mr. William Henry Allen\n",
      "                             ...                        \n",
      "882                                 Rev. Juozas Montvila\n",
      "883                          Miss. Margaret Edith Graham\n",
      "884                       Miss. Catherine Helen Johnston\n",
      "885                                 Mr. Karl Howell Behr\n",
      "886                                   Mr. Patrick Dooley\n",
      "Name: Name, Length: 887, dtype: object}\n",
      "ì²«ë²ˆì§¸ í–‰ ì¶œë ¥\n",
      "ì˜¤ë¥˜ ë°œìƒ: Unsupported request type '```\n",
      "row'.                         Please check the format instructions.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE \n"
     ]
    }
   ],
   "source": [
    "# ì²´ì¸ ìƒì„±\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ëª¨ë¸ ì‘ë‹µ ë°›ê¸°\n",
    "try:\n",
    "    # **Name ì—´ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('Name ì»¬ëŸ¼ ì¶œë ¥')\n",
    "    df_query = \"Show the Name column\"\n",
    "\n",
    "    parser_output = chain.invoke({\"query\": df_query})\n",
    "    print(type(parser_output))\n",
    "    print(parser_output)\n",
    "\n",
    "    # **ì²«ë²ˆì§¸ í–‰ì„ í‘œì‹œí•˜ì‹­ì‹œì˜¤.**\n",
    "    print('ì²«ë²ˆì§¸ í–‰ ì¶œë ¥')\n",
    "    df_query2 = \"Show first row\"\n",
    "\n",
    "    parser_output2 = chain.invoke({\"query\": df_query2})\n",
    "    print(parser_output2)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87620437",
   "metadata": {},
   "source": [
    "### StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30aca593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['query'] input_types={} partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"data\": string  // A list of dictionaries representing table rows.\\n}\\n```'} template='\\n    You are an AI assistant that generates tabular data. \\n    You must return the data in JSON format that follows this schema:\\n\\n    {format_instructions}\\n\\n    **User Query:**\\n    {query}\\n    '\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = ChatOpenAI(temperature=0, model_name=\"gpt-4o\")\n",
    "# model = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "#     model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# ì‘ë‹µ ìŠ¤í‚¤ë§ˆ ì •ì˜ {data : [{},{},{}] }\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"data\", description=\"A list of dictionaries representing table rows.\"),\n",
    "]\n",
    "\n",
    "# Output Parser ì„¤ì •\n",
    "parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are an AI assistant that generates tabular data. \n",
    "    You must return the data in JSON format that follows this schema:\n",
    "    \n",
    "    {format_instructions}\n",
    "        \n",
    "    **User Query:**\n",
    "    {query}\n",
    "    \"\"\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c521b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì²´ì¸ ìƒì„± (í”„ë¡¬í”„íŠ¸ â†’ ëª¨ë¸ â†’ OutputParser)\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# ì‹¤í–‰ í•¨ìˆ˜\n",
    "def generate_dataframe(user_query):\n",
    "    try:\n",
    "        # ëª¨ë¸ í˜¸ì¶œ\n",
    "        json_response = chain.invoke({\"query\": user_query})\n",
    "        print(json_response)\n",
    "        \n",
    "        # ëª¨ë¸ì´ ë°˜í™˜í•œ JSONì„ Pandas DataFrameìœ¼ë¡œ ë³€í™˜\n",
    "        df = pd.DataFrame(json_response[\"data\"])\n",
    "\n",
    "        # ê²°ê³¼ ì¶œë ¥\n",
    "        print(\"\\nğŸ”¹ Generated DataFrame:\\n\")\n",
    "        return df\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a3a7861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
      "{'data': [{'District': 'Gangnam-gu', 'Average Price': 1500000000, 'Number of Transactions': 1200, 'Year-over-Year Change (%)': 3.5}, {'District': 'Jongno-gu', 'Average Price': 950000000, 'Number of Transactions': 800, 'Year-over-Year Change (%)': 2.1}, {'District': 'Mapo-gu', 'Average Price': 1100000000, 'Number of Transactions': 950, 'Year-over-Year Change (%)': 4.0}, {'District': 'Songpa-gu', 'Average Price': 1300000000, 'Number of Transactions': 1100, 'Year-over-Year Change (%)': 3.8}, {'District': 'Yongsan-gu', 'Average Price': 1400000000, 'Number of Transactions': 700, 'Year-over-Year Change (%)': 2.5}, {'District': 'Seocho-gu', 'Average Price': 1450000000, 'Number of Transactions': 1150, 'Year-over-Year Change (%)': 3.2}, {'District': 'Gwanak-gu', 'Average Price': 800000000, 'Number of Transactions': 900, 'Year-over-Year Change (%)': 1.8}, {'District': 'Dongdaemun-gu', 'Average Price': 750000000, 'Number of Transactions': 850, 'Year-over-Year Change (%)': 2.0}, {'District': 'Seodaemun-gu', 'Average Price': 900000000, 'Number of Transactions': 780, 'Year-over-Year Change (%)': 2.7}, {'District': 'Jung-gu', 'Average Price': 1000000000, 'Number of Transactions': 650, 'Year-over-Year Change (%)': 3.0}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n",
      "(10, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>District</th>\n",
       "      <th>Average Price</th>\n",
       "      <th>Number of Transactions</th>\n",
       "      <th>Year-over-Year Change (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gangnam-gu</td>\n",
       "      <td>1500000000</td>\n",
       "      <td>1200</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jongno-gu</td>\n",
       "      <td>950000000</td>\n",
       "      <td>800</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mapo-gu</td>\n",
       "      <td>1100000000</td>\n",
       "      <td>950</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Songpa-gu</td>\n",
       "      <td>1300000000</td>\n",
       "      <td>1100</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yongsan-gu</td>\n",
       "      <td>1400000000</td>\n",
       "      <td>700</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seocho-gu</td>\n",
       "      <td>1450000000</td>\n",
       "      <td>1150</td>\n",
       "      <td>3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gwanak-gu</td>\n",
       "      <td>800000000</td>\n",
       "      <td>900</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dongdaemun-gu</td>\n",
       "      <td>750000000</td>\n",
       "      <td>850</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Seodaemun-gu</td>\n",
       "      <td>900000000</td>\n",
       "      <td>780</td>\n",
       "      <td>2.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jung-gu</td>\n",
       "      <td>1000000000</td>\n",
       "      <td>650</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        District  Average Price  Number of Transactions  \\\n",
       "0     Gangnam-gu     1500000000                    1200   \n",
       "1      Jongno-gu      950000000                     800   \n",
       "2        Mapo-gu     1100000000                     950   \n",
       "3      Songpa-gu     1300000000                    1100   \n",
       "4     Yongsan-gu     1400000000                     700   \n",
       "5      Seocho-gu     1450000000                    1150   \n",
       "6      Gwanak-gu      800000000                     900   \n",
       "7  Dongdaemun-gu      750000000                     850   \n",
       "8   Seodaemun-gu      900000000                     780   \n",
       "9        Jung-gu     1000000000                     650   \n",
       "\n",
       "   Year-over-Year Change (%)  \n",
       "0                        3.5  \n",
       "1                        2.1  \n",
       "2                        4.0  \n",
       "3                        3.8  \n",
       "4                        2.5  \n",
       "5                        3.2  \n",
       "6                        1.8  \n",
       "7                        2.0  \n",
       "8                        2.7  \n",
       "9                        3.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [ì˜ˆì œ 1] 2024ë…„ ìƒë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±\n",
    "print('2024ë…„ í•˜ë°˜ê¸° ì„œìš¸ ì•„íŒŒíŠ¸ í‰ê·  ë§¤ë§¤ ê°€ê²© ë°ì´í„° ìƒì„±')\n",
    "df_seoul_housing = generate_dataframe(\n",
    "    \"Create a dataset of the average apartment sale prices in Seoul for the second half of 2024 with columns: District (êµ¬), Average Price (in KRW), Number of Transactions, and Year-over-Year Change (%).\"\n",
    ")\n",
    "print(df_seoul_housing.shape)\n",
    "df_seoul_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14c8b81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
      "{'data': [{'Station Name': 'Gangnam', 'Line Number': 'Line 2', 'Daily Passenger Volume': 150000, 'Weekday vs Weekend Ratio': '3:1'}, {'Station Name': 'Jamsil', 'Line Number': 'Line 2', 'Daily Passenger Volume': 130000, 'Weekday vs Weekend Ratio': '2.8:1'}, {'Station Name': 'Hongdae', 'Line Number': 'Line 2', 'Daily Passenger Volume': 120000, 'Weekday vs Weekend Ratio': '2.5:1'}, {'Station Name': 'Seoul Station', 'Line Number': 'Line 1', 'Daily Passenger Volume': 110000, 'Weekday vs Weekend Ratio': '3.2:1'}, {'Station Name': 'Samseong', 'Line Number': 'Line 2', 'Daily Passenger Volume': 105000, 'Weekday vs Weekend Ratio': '2.9:1'}, {'Station Name': 'Express Bus Terminal', 'Line Number': 'Line 3', 'Daily Passenger Volume': 100000, 'Weekday vs Weekend Ratio': '3:1'}, {'Station Name': 'Yeouido', 'Line Number': 'Line 5', 'Daily Passenger Volume': 95000, 'Weekday vs Weekend Ratio': '2.7:1'}, {'Station Name': 'Myeongdong', 'Line Number': 'Line 4', 'Daily Passenger Volume': 90000, 'Weekday vs Weekend Ratio': '2.6:1'}, {'Station Name': 'Dongdaemun', 'Line Number': 'Line 4', 'Daily Passenger Volume': 85000, 'Weekday vs Weekend Ratio': '2.4:1'}, {'Station Name': 'Gwanghwamun', 'Line Number': 'Line 5', 'Daily Passenger Volume': 80000, 'Weekday vs Weekend Ratio': '2.5:1'}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°')\n",
    "# [ì˜ˆì œ 2] 2024ë…„ ì„œìš¸ ì§€í•˜ì² ì—­ë³„ ìœ ë™ ì¸êµ¬ ë°ì´í„°\n",
    "df_seoul_subway = generate_dataframe(\n",
    "    \"Generate a dataset of the top 10 busiest subway stations in Seoul in 2024 with columns: Station Name, Line Number, Daily Passenger Volume, and Weekday vs Weekend Ratio.\"\n",
    ")\n",
    "if df_seoul_subway is not None:\n",
    "    df_seoul_subway.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "757e7282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
      "{'data': [{'Brand Name': 'CU', 'Number of Stores': 15000, 'Total Revenue (in billion KRW)': 5000, 'Market Share (%)': 35.0}, {'Brand Name': 'GS25', 'Number of Stores': 14000, 'Total Revenue (in billion KRW)': 4800, 'Market Share (%)': 33.5}, {'Brand Name': '7-Eleven', 'Number of Stores': 10000, 'Total Revenue (in billion KRW)': 3000, 'Market Share (%)': 20.0}, {'Brand Name': 'Emart24', 'Number of Stores': 5000, 'Total Revenue (in billion KRW)': 1500, 'Market Share (%)': 7.5}, {'Brand Name': 'Ministop', 'Number of Stores': 3000, 'Total Revenue (in billion KRW)': 700, 'Market Share (%)': 4.0}]}\n",
      "\n",
      "ğŸ”¹ Generated DataFrame:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand Name</th>\n",
       "      <th>Number of Stores</th>\n",
       "      <th>Total Revenue (in billion KRW)</th>\n",
       "      <th>Market Share (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CU</td>\n",
       "      <td>15000</td>\n",
       "      <td>5000</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GS25</td>\n",
       "      <td>14000</td>\n",
       "      <td>4800</td>\n",
       "      <td>33.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7-Eleven</td>\n",
       "      <td>10000</td>\n",
       "      <td>3000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emart24</td>\n",
       "      <td>5000</td>\n",
       "      <td>1500</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ministop</td>\n",
       "      <td>3000</td>\n",
       "      <td>700</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Brand Name  Number of Stores  Total Revenue (in billion KRW)  \\\n",
       "0         CU             15000                            5000   \n",
       "1       GS25             14000                            4800   \n",
       "2   7-Eleven             10000                            3000   \n",
       "3    Emart24              5000                            1500   \n",
       "4   Ministop              3000                             700   \n",
       "\n",
       "   Market Share (%)  \n",
       "0              35.0  \n",
       "1              33.5  \n",
       "2              20.0  \n",
       "3               7.5  \n",
       "4               4.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜')\n",
    "# [ì˜ˆì œ 3] í•œêµ­ 5ëŒ€ í¸ì˜ì  ë¸Œëœë“œë³„ 2024ë…„ ë§¤ì¶œ ë° ì í¬ ìˆ˜\n",
    "df_korean_convenience_stores = generate_dataframe(\n",
    "    \"Create a dataset of the top 5 convenience store brands in Korea in 2024 with columns: Brand Name, Number of Stores, Total Revenue (in billion KRW), and Market Share (%).\"\n",
    ")\n",
    "df_korean_convenience_stores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf9d28",
   "metadata": {},
   "source": [
    "### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d99c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d433a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¶”ì²œ ì˜í™”: The Sixth Sense (1999)\n",
      "ì¶”ì²œ ì´ìœ : 1990ë…„ëŒ€ ëŒ€í‘œì ì¸ ì‹¬ë¦¬ ê³µí¬ ì˜í™”ë¡œ, ë°˜ì „ ê²°ë§ì´ ì¸ìƒì ì…ë‹ˆë‹¤.\n",
      "ì¥ë¥´: Mystery, Thriller, Horror\n",
      "ì˜ˆìƒ í‰ì : 8.5/10\n"
     ]
    }
   ],
   "source": [
    "# ì¶œë ¥ êµ¬ì¡°ë¥¼ ì •ì˜í•˜ëŠ” Pydantic ëª¨ë¸\n",
    "class MovieRecommendation(BaseModel):\n",
    "    movie_title: str = Field(description=\"ì¶”ì²œ ì˜í™” ì œëª©\")\n",
    "    reason: str = Field(description=\"ì¶”ì²œ ì´ìœ \")\n",
    "    genre: List[str] = Field(description=\"ì˜í™” ì¥ë¥´\")\n",
    "    estimated_rating: float = Field(description=\"10ì  ë§Œì ì—ì„œ ì˜ˆìƒ í‰ì \")\n",
    "    \n",
    "# Pydantic ì¶œë ¥ íŒŒì„œ ì´ˆê¸°í™”\n",
    "parser = PydanticOutputParser(pydantic_object=MovieRecommendation)\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì„¤ì •\n",
    "template = \"\"\"\n",
    "ë‹¤ìŒ ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì˜í™”ë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
    "ìš”ì²­: {query}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# íŒŒì„œì˜ ì§€ì‹œì‚¬í•­ì„ í”„ë¡¬í”„íŠ¸ì— ì£¼ì…\n",
    "prompt = prompt.partial(\n",
    "    format_instructions=parser.get_format_instructions()\n",
    ")\n",
    "\n",
    "# ChatOpenAI ëª¨ë¸ ì´ˆê¸°í™”\n",
    "#model = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "model = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API ì—”ë“œí¬ì¸íŠ¸\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AIì™€ ë™ì¼í•œ ëª¨ë¸\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# ì²´ì¸ êµ¬ì„± ë° ì‹¤í–‰\n",
    "query = \"1990ë…„ëŒ€ í´ë˜ì‹í•œ ëŠë‚Œì˜ ê³µí¬ ì˜í™” ì¶”ì²œí•´ì¤˜\"\n",
    "chain = prompt | model | parser\n",
    "output = chain.invoke({\"query\": query})\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"ì¶”ì²œ ì˜í™”: {output.movie_title}\")\n",
    "print(f\"ì¶”ì²œ ì´ìœ : {output.reason}\")\n",
    "print(f\"ì¥ë¥´: {', '.join(output.genre)}\")\n",
    "print(f\"ì˜ˆìƒ í‰ì : {output.estimated_rating}/10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f508e45c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-basic-kGdHTiMZ-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
